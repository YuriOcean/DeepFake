[INFO] 2025-10-05 19:00:02,848 run: Running torch.distributed.run with args: ['/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/run.py', '--standalone', '--nnodes=1', '--nproc_per_node=2', '../training_scripts/train.py', '--config', '/data/disk2/yer/ForensicHub/ForensicHub/statics/bisai/focal_train_coverage.yaml']
[INFO] 2025-10-05 19:00:02,850 run: 
**************************************
Rendezvous info:
--rdzv_backend=c10d --rdzv_endpoint=localhost:29400 --rdzv_id=e0481304-0260-402f-829e-3744d88b3cbc
**************************************

[INFO] 2025-10-05 19:00:02,850 run: Using nproc_per_node=2.
[INFO] 2025-10-05 19:00:02,850 api: Starting elastic_operator with launch configs:
  entrypoint       : ../training_scripts/train.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 2
  run_id           : e0481304-0260-402f-829e-3744d88b3cbc
  rdzv_backend     : c10d
  rdzv_endpoint    : localhost:29400
  rdzv_configs     : {'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

[INFO] 2025-10-05 19:00:02,851 c10d_rendezvous_backend: Process 29711 hosts the TCP store for the C10d rendezvous backend.
[INFO] 2025-10-05 19:00:02,853 local_elastic_agent: log directory set to: /tmp/torchelastic_xnvbbrzm/e0481304-0260-402f-829e-3744d88b3cbc_dmfzyrlz
[INFO] 2025-10-05 19:00:02,853 api: [default] starting workers for entrypoint: python
[INFO] 2025-10-05 19:00:02,853 api: [default] Rendezvous'ing worker group
[INFO] 2025-10-05 19:00:02,853 dynamic_rendezvous: The node 'haida-KI4208G_29711_0' attempts to join the next round of the rendezvous 'e0481304-0260-402f-829e-3744d88b3cbc'.
[INFO] 2025-10-05 19:00:02,964 dynamic_rendezvous: The node 'haida-KI4208G_29711_0' has joined round 0 of the rendezvous 'e0481304-0260-402f-829e-3744d88b3cbc' as rank 0 in a world of size 1.
/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
[INFO] 2025-10-05 19:00:02,964 api: [default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=haida-KI4208G
  master_port=44039
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1]
  role_ranks=[0, 1]
  global_ranks=[0, 1]
  role_world_sizes=[2, 2]
  global_world_sizes=[2, 2]

[INFO] 2025-10-05 19:00:02,964 api: [default] Starting worker group
[INFO] 2025-10-05 19:00:02,965 __init__: Setting worker0 reply file to: /tmp/torchelastic_xnvbbrzm/e0481304-0260-402f-829e-3744d88b3cbc_dmfzyrlz/attempt_0/0/error.json
[INFO] 2025-10-05 19:00:02,965 __init__: Setting worker1 reply file to: /tmp/torchelastic_xnvbbrzm/e0481304-0260-402f-829e-3744d88b3cbc_dmfzyrlz/attempt_0/1/error.json
/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/IMDLBenCo/training_scripts/trainer/trainer.py:25: UserWarning: HOPE YOU TO READ: Starting from IMDLBenCo version v0.1.31, we have discovered a misdefinition regarding the --if_not_amp parameter in the argument parser. For more details, please refer to: https://github.com/scu-zjz/IMDLBenCo/issues/89. As a result, if you use the train.py script generated by an earlier version of 'benco init' before v0.1.30, along with the latest version of trainer.py, it may lead to AMP (Automatic Mixed Precision) being incorrectly enabled or disabled. We recommend updating to the latest version(after v0.1.31, include) of IMDLBenCo and re-initializing the project using 'benco init' to ensure that the --if_not_amp parameter is correctly defined.  Or for already initialized projects, please manually modify the action of the --if_not_amp parameter in train.py to 'store_true' to ensure correct logic.  We apologize for any inconvenience this may have caused.!!!!!!
  warnings.warn(
/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/IMDLBenCo/training_scripts/trainer/trainer.py:25: UserWarning: HOPE YOU TO READ: Starting from IMDLBenCo version v0.1.31, we have discovered a misdefinition regarding the --if_not_amp parameter in the argument parser. For more details, please refer to: https://github.com/scu-zjz/IMDLBenCo/issues/89. As a result, if you use the train.py script generated by an earlier version of 'benco init' before v0.1.30, along with the latest version of trainer.py, it may lead to AMP (Automatic Mixed Precision) being incorrectly enabled or disabled. We recommend updating to the latest version(after v0.1.31, include) of IMDLBenCo and re-initializing the project using 'benco init' to ensure that the --if_not_amp parameter is correctly defined.  Or for already initialized projects, please manually modify the action of the --if_not_amp parameter in train.py to 'store_true' to ensure correct logic.  We apologize for any inconvenience this may have caused.!!!!!!
  warnings.warn(
[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.
[W ProcessGroupNCCL.cpp:1569] Rank 1 using best-guess GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
/data/disk2/yer/ForensicHub/ForensicHub/tasks/bisai/dataset/coverage_dataset.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask_np, dtype=torch.long).unsqueeze(0)
Traceback (most recent call last):
  File "../training_scripts/train.py", line 278, in <module>
    main(args, model_args, train_dataset_args, test_dataset_args, transform_args, evaluator_args)
  File "../training_scripts/train.py", line 193, in main
    train_stats = train_one_epoch(
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/IMDLBenCo/training_scripts/trainer/trainer.py", line 84, in train_one_epoch
    output_dict = model(**data_dict, 
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
TypeError: forward() got an unexpected keyword argument 'if_predcit_label'
Traceback (most recent call last):
  File "../training_scripts/train.py", line 278, in <module>
    main(args, model_args, train_dataset_args, test_dataset_args, transform_args, evaluator_args)
  File "../training_scripts/train.py", line 193, in main
    train_stats = train_one_epoch(
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/IMDLBenCo/training_scripts/trainer/trainer.py", line 84, in train_one_epoch
    output_dict = model(**data_dict, 
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
TypeError: forward() got an unexpected keyword argument 'if_predcit_label'
[INFO] 2025-10-05 19:25:30,300 dynamic_rendezvous: The node 'haida-KI4208G_29711_0' has closed the rendezvous 'e0481304-0260-402f-829e-3744d88b3cbc'.
Traceback (most recent call last):
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/run.py", line 637, in <module>
    main()
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/run.py", line 629, in main
    run(args)
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/run.py", line 621, in run
    elastic_launch(
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 116, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 238, in launch_agent
    result = agent.run()
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 700, in run
    result = self._invoke_run(role)
  File "/var/tmp/yer/anaconda3/envs/rethinking/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 828, in _invoke_run
    time.sleep(monitor_interval)
KeyboardInterrupt
